{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f77fec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_curve, auc, f1_score, roc_curve\n",
    "from PIL import Image, ImageFile\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33393de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings and configure PIL\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b62ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "train_fake_dir = r'C:\\Desktop\\Major\\train_data\\fake'\n",
    "train_real_dir = r'C:\\Desktop\\Major\\train_data\\real'\n",
    "test_fake_dir = r'C:\\Desktop\\Major\\test_data\\fake'\n",
    "test_real_dir = r'C:\\Desktop\\Major\\test_data\\real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263f3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.4),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07480cf9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "test_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76809315",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess_and_augment(image_path, transform):\n",
    "    image = Image.open(image_path)\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    augmented = transform(image=np.array(image))['image']\n",
    "    return augmented.permute(1, 2, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97800ae3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def sequential_train_generator(fake_dir, real_dir, batch_size, transform):\n",
    "    valid_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    fake_files = [os.path.join(fake_dir, f) for f in os.listdir(fake_dir) if f.lower().endswith(valid_extensions)]\n",
    "    real_files = [os.path.join(real_dir, f) for f in os.listdir(real_dir) if f.lower().endswith(valid_extensions)]\n",
    "    batch_half = batch_size // 2\n",
    "    \n",
    "    while True:\n",
    "        np.random.shuffle(fake_files)\n",
    "        np.random.shuffle(real_files)\n",
    "        for i in range(100):  # Fixed to 100 steps per epoch\n",
    "            batch_fake = fake_files[i*batch_half % len(fake_files):(i+1)*batch_half % len(fake_files)]\n",
    "            batch_real = real_files[i*batch_half % len(real_files):(i+1)*batch_half % len(real_files)]\n",
    "            batch_files = batch_fake + batch_real\n",
    "            batch_labels = [0]*len(batch_fake) + [1]*len(batch_real)\n",
    "            \n",
    "            batch_images = np.stack([preprocess_and_augment(f, transform) for f in batch_files], axis=0)\n",
    "            yield batch_images, np.array(batch_labels, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82cafb97",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def deterministic_data_generator(fake_dir, real_dir, batch_size, transform):\n",
    "    valid_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    fake_files = sorted([os.path.join(fake_dir, f) for f in os.listdir(fake_dir) if f.lower().endswith(valid_extensions)])\n",
    "    real_files = sorted([os.path.join(real_dir, f) for f in os.listdir(real_dir) if f.lower().endswith(valid_extensions)])\n",
    "    file_list = fake_files + real_files\n",
    "    labels_list = [0]*len(fake_files) + [1]*len(real_files)\n",
    "    \n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        batch_files = file_list[i:i+batch_size]\n",
    "        batch_labels = labels_list[i:i+batch_size]\n",
    "        batch_images = np.stack([preprocess_and_augment(f, transform) for f in batch_files], axis=0)\n",
    "        yield batch_images, np.array(batch_labels, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47097528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 100\n",
    "epochs = 30\n",
    "steps_per_epoch_train = 100\n",
    "steps_test = math.ceil(\n",
    "    (len([f for f in os.listdir(test_fake_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]) + \n",
    "     len([f for f in os.listdir(test_real_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])) \n",
    "    / batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb508ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:120]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67be6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.02)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15ad14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-4,\n",
    "    decay_steps=steps_per_epoch_train * 20,\n",
    "    alpha=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "119c4ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c878c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks (removed EarlyStopping)\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_model.keras', monitor='val_auc', mode='max', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b570f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train_generator = sequential_train_generator(train_fake_dir, train_real_dir, batch_size, train_transform)\n",
    "test_generator = deterministic_data_generator(test_fake_dir, test_real_dir, batch_size, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=steps_test,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc31741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and evaluate\n",
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_true = []\n",
    "for batch_images, batch_labels in test_generator:\n",
    "    preds = model.predict(batch_images).flatten()\n",
    "    all_preds.extend(preds)\n",
    "    all_true.extend(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (np.array(all_preds) > 0.5).astype('int32')\n",
    "print(f\"ROC AUC: {roc_auc_score(all_true, all_preds):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(all_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting (same as your original)\n",
    "conf_matrix = confusion_matrix(all_true, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\", \n",
    "            xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ef934",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(all_true, all_preds)\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_score(all_true, all_preds):.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(all_true, all_preds)\n",
    "precision, recall, _ = precision_recall_curve(all_true, all_preds)\n",
    "pr_auc = auc(recall, precision)\n",
    "f1 = f1_score(all_true, y_pred)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4291a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save the confusion matrix.\n",
    "conf_matrix = confusion_matrix(all_true, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\", xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save the ROC curve.\n",
    "fpr, tpr, _ = roc_curve(all_true, all_preds)\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33710d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy over epochs.\n",
    "plt.figure(figsize=(8, 6))\n",
    "epochs_range = range(len(history.history['accuracy']))\n",
    "plt.plot(epochs_range, history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('training_validation_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss improvement (initial loss minus current loss) over epochs.\n",
    "initial_train_loss = history.history['loss'][0]\n",
    "initial_val_loss = history.history['val_loss'][0]\n",
    "loss_improvement_train = initial_train_loss - np.array(history.history['loss'])\n",
    "loss_improvement_val = initial_val_loss - np.array(history.history['val_loss'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs_range, loss_improvement_train, label='Training Loss Improvement', color='blue')\n",
    "plt.plot(epochs_range, loss_improvement_val, label='Validation Loss Improvement', color='orange')\n",
    "plt.title('Training and Validation Loss Improvement')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Improvement (Initial Loss - Current Loss)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_improvement_curve.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
